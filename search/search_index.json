{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Path Generator","text":"<p>A Python library for generating human-like mouse movement paths using PD (Proportional-Derivative) control.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Human-like trajectories - Curved paths with natural velocity profiles</li> <li>Fitts's Law compliance - Automatic deceleration near targets</li> <li>Configurable behavior - Tune speed, curvature, noise, and more</li> <li>Resolution independent - Works across different screen sizes</li> <li>Overshoot simulation - Optional target overshoot and correction</li> </ul>"},{"location":"#installation","title":"Installation","text":"BaseServer/PlaygroundWindows EmulationAll Extras <pre><code>pip install pathgenerator\n</code></pre> <pre><code>pip install pathgenerator[server]\n</code></pre> <pre><code>pip install pathgenerator[windows]\n</code></pre> <pre><code>pip install pathgenerator[server,windows]\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from pathgenerator import PDPathGenerator\n\n# Create generator\ngen = PDPathGenerator()\n# gen = PDPathGenerator('params.json') to load params from a json file\n\n# Define points\nstart_x, start_y = 100, 200\nend_x, end_y = 900, 1000\n\n# Generate a path\npath, prog_list, steps, params = gen.generate_path(\n    start_x=start_x, start_y=start_y,\n    end_x=end_x, end_y=end_y,\n    offset_x=0, offset_y=0  # Optional offset if you target a relative area\n)\n\n\n# path is a numpy array of (x, y) coordinates\nfor x, y in path:\n    print(f\"Move to ({x:.1f}, {y:.1f})\")\n</code></pre>"},{"location":"#tuning-workflow-server-json","title":"Tuning Workflow (Server + JSON)","text":"<p>The easiest way to find realistic parameters is to use the interactive playground. (Requires: <code>pip install pathgenerator[server]</code>)</p> <ol> <li>Launch the server:     <pre><code>python -m pathgenerator.server\n</code></pre></li> <li>Tune settings at <code>http://127.0.0.1:8001</code>.</li> <li>Download JSON: Click \"Export Preset\" to save your settings as <code>human_relaxed.json</code>.</li> <li>Load in Python:     <pre><code># Initialize generator with your custom preset\ngen = PDPathGenerator(\"human_relaxed.json\")\n\n# All generated paths will now use those settings by default\npath, *_ = gen.generate_path(100, 100, 500, 500)\n</code></pre></li> </ol>"},{"location":"#executing-paths-windows-only","title":"Executing Paths (Windows Only)","text":"<p>The <code>PathEmulator</code> class includes a helper <code>get_position()</code> to simplify generating paths from your current mouse location.</p> <pre><code>from pathgenerator import PDPathGenerator, PathEmulator\n\n# Requires: pip install pathgenerator[windows]\nemulator = PathEmulator()\ngen = PDPathGenerator()\n\n# 1. Get current mouse position\nstart_x, start_y = emulator.get_position()\n\n# 2. Generate path to target (e.g., 500, 500)\n# calculate offset if you are targeting a window relative to screen 0,0\npath, *_ = gen.generate_path(start_x, start_y, 500, 500)\n\n# 3. Move the mouse (optional delay to control playback speed)\nemulator.execute_path(path, delay_between_points=0.001)\n</code></pre>"},{"location":"#how-it-works","title":"How It Works","text":"<p>The generator uses a unit-frame approach:</p> <ol> <li>Transform the problem so start=(0,0) and target=(1,0)</li> <li>Simulate movement with PD control for correction</li> <li>Add human-like noise and velocity profiles</li> <li>Transform back to screen coordinates</li> </ol> <p>See the Algorithm Guide for a detailed explanation.</p>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Algorithm Guide - Understand how path generation works</li> <li>Basic Usage - Common usage patterns</li> <li>Tuning Parameters - Fine-tune path characteristics</li> <li>API Reference - Full API documentation</li> </ul>"},{"location":"path_generation/","title":"Path Generation Algorithm","text":"<p>This document explains how the <code>PDPathGenerator</code> creates human-like mouse paths using a PD (Proportional-Derivative) controller approach.</p>"},{"location":"path_generation/#overview","title":"Overview","text":"<p>The generator simulates how a human moves a mouse cursor from point A to point B. Rather than moving in a perfect straight line, humans exhibit:</p> <ul> <li>Initial direction error - We don't aim perfectly at the start</li> <li>Curved trajectories - Natural arc toward the target</li> <li>Velocity profiles - Fast in the middle, slow near the target (Fitts's Law)</li> <li>Micro-corrections - Small adjustments along the way</li> <li>Hand tremor - Slight noise/wobble in movement</li> <li>Overshoot - Sometimes going past the target and correcting</li> </ul>"},{"location":"path_generation/#the-unit-frame-approach","title":"The Unit-Frame Approach","text":"<p>Instead of working directly in screen coordinates, we transform the problem into a normalized \"unit frame\":</p> <pre><code>Screen Space                    Unit Space\n\n    target (500, 300)               \n       \u25cf                        start        target\n      /                           \u25cf------------\u25cf\n     /                          (0, 0)       (1, 0)\n    /                            \n   \u25cf                            \nstart (100, 200)              \n</code></pre> Deep Dive: The Math Behind <code>get_unit_transform</code> <p>The <code>get_unit_transform</code> function is the mathematical foundation of the coordinate system. Its goal is to take a movement happening at any angle or distance and translate it into a standardized \"unit frame\" where the start is always \\((0,0)\\) and the target is always \\((1,0)\\).</p> <p>Here is a step-by-step breakdown of how the code achieves this:</p> <p>Why? This makes the algorithm resolution-independent. All the physics and tuning works the same whether you're moving 50 pixels or 500 pixels.</p> <p>The process:</p> Step 1: Normalize <p>Rotate and scale the coordinate system so that start\u2192target becomes a simple horizontal line from (0,0) to (1,0).</p> <p>This transforms any diagonal movement into a standardized problem where we only need to move \"right\" along the X-axis.</p> <p></p> Step 2: Simulate <p>Run the path simulation in this simplified unit space. The controller only needs to:</p> <ul> <li>Move forward (increase X from 0 toward 1)</li> <li>Correct Y deviations back toward 0</li> <li>Apply human-like noise and velocity profiles</li> </ul> <p></p> Step 3: Transform Back <p>Apply the inverse rotation and scaling to transform the simulated path back to screen coordinates.</p> <p>The curved path in unit space becomes a curved path between your actual start and target points.</p> <p></p>"},{"location":"path_generation/#1-coordinate-unpacking","title":"1. Coordinate Unpacking","text":"<pre><code>sx, sy = start\ntx, ty = target\n</code></pre> <p>The function receives two numpy arrays as input:</p> <ul> <li><code>start</code>: The mouse's current position in screen pixels, e.g., <code>np.array([100, 200])</code></li> <li><code>target</code>: Where the mouse needs to go, e.g., <code>np.array([500, 300])</code></li> </ul> <p>It unpacks these into individual \\(x\\) and \\(y\\) variables: Start \\((sx, sy)\\) and Target \\((tx, ty)\\).</p>"},{"location":"path_generation/#2-finding-the-displacement-vector","title":"2. Finding the Displacement Vector","text":"<pre><code>v = np.array([tx - sx, ty - sy], dtype=np.float32)\n</code></pre> <p>It calculates the displacement vector \\(\\vec{v}\\) by subtracting the start from the target.</p> <p>This vector represents the raw direction and distance the mouse needs to travel in screen pixels.</p>"},{"location":"path_generation/#3-calculating-the-euclidean-distance-d","title":"3. Calculating the Euclidean Distance (\\(D\\))","text":"<pre><code>D = float(np.hypot(v[0], v[1])) or 1.0\n</code></pre> <p><code>np.hypot</code> calculates the magnitude (length) of vector \\(\\vec{v}\\) using the Pythagorean theorem:</p> \\[D = \\sqrt{v_x^2 + v_y^2}\\] <p>The <code>or 1.0</code> is a safety mechanism to prevent \"division by zero\" errors if the start and target points are identical.</p> <p>This distance \\(D\\) becomes the scaling factor used later to shrink the path down to a unit length of \\(1.0\\).</p>"},{"location":"path_generation/#4-vector-normalization","title":"4. Vector Normalization","text":"<pre><code>v /= D\nc, s = v[0], v[1]\n</code></pre> <p>By dividing the displacement vector by its own distance, the function creates a unit vector (a vector with a length of exactly \\(1.0\\)).</p> <p>In trigonometry, the \\(x\\) and \\(y\\) components of a unit vector are equivalent to the \\(\\cos(\\theta)\\) and \\(\\sin(\\theta)\\) of the angle of that vector:</p> \\[\\hat{v} = (\\cos\\theta, \\sin\\theta)\\] <p>The variables <code>c</code> and <code>s</code> now store these trigonometric values for the rotation matrix.</p>"},{"location":"path_generation/#5-constructing-the-rotation-matrix-r","title":"5. Constructing the Rotation Matrix (\\(R\\))","text":"<pre><code>R = np.array([[c, s],\n              [-s, c]], dtype=np.float32)\n</code></pre> <p>The function builds a \\(2 \\times 2\\) rotation matrix:</p> \\[R = \\begin{bmatrix} \\cos\\theta &amp; \\sin\\theta \\\\ -\\sin\\theta &amp; \\cos\\theta \\end{bmatrix}\\] <p>This specific configuration is designed to rotate the entire coordinate system by \\(-\\theta\\).</p> <p>When applied to any point, it \"un-rotates\" the world so that the target point, regardless of where it was originally, now sits perfectly on the positive X-axis relative to the start point.</p>"},{"location":"path_generation/#summary-of-the-output","title":"Summary of the Output","text":"<p>The function returns two pieces of data that allow the <code>PDPathGenerator</code> to work in a simplified environment:</p> Output Purpose \\(R\\) (Rotation) Tells the generator how to align the world so the target is \"straight ahead\" \\(D\\) (Distance) Tells the generator how much to scale the movement so the target is exactly \"one unit\" away"},{"location":"path_generation/#conversion-formulas","title":"Conversion Formulas","text":"<p>Screen \u2192 Unit: <pre><code>P_unit = (P_screen - start) @ R.T / D\n</code></pre></p> <p>Unit \u2192 Screen: <pre><code>P_screen = start + (P_unit * D) @ R\n</code></pre></p>"},{"location":"path_generation/#transformation-pipeline","title":"Transformation Pipeline","text":"<p>The physics simulation loop logically applies these transformations in order during every iteration:</p> <pre><code>flowchart LR\n    A[Velocity] --&gt; B[Feedforward] --&gt; C[PD] --&gt; D[Noise] --&gt; E[Stabilize] --&gt; F[Limit] --&gt; G[Integrate] --&gt; H{Keep?}\n    H --&gt;|Y| I[Path]\n    H --&gt;|N| J[Skip]</code></pre> <p>Select a step below to see its implementation:</p> 1. Feedforward2. PD Correction3. Noise4. Stabilization5. Step Limiting6. Integration7. Point Density <p>Feedforward + Braking</p> <p>Implementation: Inlined physics calculation</p> <p>Maintains forward motion with Fitts's Law deceleration. Humans naturally slow down as they approach a target.</p> <pre><code>dist_rem = 1.0 - progress\nbrake = clip(dist_rem * 4.0, 0.15, 1.0)\nv_unit = direction * (mouse_velocity * brake)\n</code></pre> Progress Brake Factor 0-75% 1.0 (full speed) 85% 0.6 (slowing) 95% 0.2 (crawling) <p>PD Correction</p> <p>Implementation: Inlined physics calculation</p> <p>Steers toward target using proportional-integral control with adaptive gain.</p> <pre><code># Blended KP based on progress\ncurrent_kp = weight_far * kp_start + weight_near * kp_end\n\n# Error toward target (and arc)\nerr_x = 1.0 - P_unit[0]\nerr_y = ideal_y - P_unit[1]\n\n# Apply correction\nv_unit += current_kp * 20.0 * err_unit + ki * err_sum\n</code></pre> <p>Arc Trajectory: When <code>arc_strength &gt; 0</code>, the path follows a sine curve for natural curvature.</p> <p>Noise (Ornstein-Uhlenbeck)</p> <p>Implementation: Inlined physics calculation</p> <p>Smooth, correlated random perturbations simulating hand tremor.</p> <pre><code>theta = 0.15  # Mean reversion rate\nsigma = noise_strength * 0.002\n\n# Noise decays near target\nnoise_factor = (1.0 - progress) ** 1.3\n\n# Update: pull toward zero + random kick\nnoise_state += (-theta * noise_state) + (sigma * random)\nv_unit += noise_state * noise_factor\n</code></pre> <p>The noise automatically fades near the target to ensure accurate arrival.</p> <p>Stabilization</p> <p>Implementation: Inlined physics calculation</p> <p>Damping and smoothing for natural, flowing motion.</p> <pre><code># Damping: resist sudden changes\nv_unit -= damp * (v_unit - v_previous)\n\n# Smoothing: blend with previous velocity\nalpha = 1.0 - stabilization\nv_unit = alpha * v_unit + (1 - alpha) * v_previous\n</code></pre> <p>Step Limiting</p> <p>Implementation: Inlined physics calculation</p> <p>Prevents unrealistic jumps and backward motion.</p> <pre><code># Limit magnitude (tighter near target)\nstep_limit = max_step * (0.5 + 0.5 * (1 - progress)**1.5)\nif magnitude &gt; step_limit:\n    v_unit *= step_limit / magnitude\n\n# Prevent backing up\nv_unit[0] = min(v_unit[0], 1.0 - current_x)\n</code></pre> <p>Integration</p> <p>Implementation: Inlined physics calculation</p> <p>Euler integration to update position based on velocity.</p> <pre><code>P_next = P_unit + v_unit\nP_next[0] = clip(P_next[0], -0.05, 1.0)\n\n# Convert through screen coords for consistency\nnew_px = unit_to_screen(P_next)\nP_unit = screen_to_unit(new_px)\n</code></pre> <p>Point Density</p> <p>Implementation: Inlined physics calculation</p> <p>Controls how many points are kept. Sparser at start, denser at end.</p> <pre><code># Interpolate probability\nkeep_prob = keep_prob_start + (keep_prob_end - keep_prob_start) * progress\n\n# Always keep points near end\nreturn random() &lt; keep_prob or progress &gt;= 0.97\n</code></pre> Phase Keep Probability Start (fast) ~70% End (slow) ~98% <p>Post-processing (applied after simulation):</p> <pre><code>flowchart LR\n    A[Raw Path] --&gt; B[Rotate/Scale to Target]\n    B --&gt; C[Add Overshoot]\n    C --&gt; D[Final Path]</code></pre>"},{"location":"path_generation/#post-processing","title":"Post-Processing","text":"<p>After the simulation loop completes, two final transforms are applied:</p>"},{"location":"path_generation/#rotationscale-transform","title":"Rotation/Scale Transform","text":"<p>The path is rotated and scaled to ensure it exactly hits the target endpoint. This compensates for any accumulated numerical error during simulation.</p>"},{"location":"path_generation/#overshoot","title":"Overshoot","text":"<p>Method: <code>_apply_overshoot</code></p> <p>When triggered (based on <code>overshoot_prob</code>):</p> <ol> <li>Overshoot phase: Continue past target in the movement direction (3-8% of path distance)</li> <li>Recovery phase: Curve back toward the target with eased motion</li> </ol> <pre><code>        overshoot\n           \u2197 \u27cd\ntarget \u25cf\u2190----\n       recovery\n</code></pre>"},{"location":"path_generation/#parameter-reference","title":"Parameter Reference","text":"Parameter Range Description <code>mouse_velocity</code> 0.1 - 1.0 Base velocity in unit space <code>kp_start</code> 0.0 - 0.1 Correction strength at path start <code>kp_end</code> 0.0 - 0.1 Correction strength near target <code>stabilization</code> 0.0 - 1.0 Smoothing/damping factor <code>noise</code> 0.0 - 1.0 Hand tremor intensity <code>arc_strength</code> 0.0 - 0.5 Curvature of arc trajectory <code>arc_sign</code> -1 or +1 Direction of arc (up/down in unit space) <code>keep_prob_start</code> 0.0 - 1.0 Point density at start <code>keep_prob_end</code> 0.0 - 1.0 Point density at end <code>variance</code> 0.0 - 0.5 Random variation in all parameters <code>overshoot_prob</code> 0.0 - 1.0 Chance of overshooting target <code>offset_x</code> / <code>y</code> Any Global offset added to output coordinates <code>canvas_width</code> / <code>h</code> Pixels Used for scaling variance relative to screen size <p>For detailed presets and tuning examples, see Tuning Parameters.</p>"},{"location":"api/generator/","title":"Generator Module","text":"<p>The main path generation class.</p>"},{"location":"api/generator/#pathgenerator.generator.PDPathGenerator","title":"<code>PDPathGenerator</code>","text":"<p>Human-like mouse path generator using PD control.</p> <p>Uses a standard unit-frame approach for resolution-independent path generation:</p> <ol> <li>Transform the problem so start=(0,0) and target=(1,0)</li> <li>Simulate movement with feedforward velocity and PD correction (inlined for performance)</li> <li>Apply human-like noise, stabilization, and velocity profiles</li> <li>Transform back to screen coordinates</li> </ol> <p>The physics simulation loop integrates several behaviors:</p> <ol> <li>Feedforward + braking (Fitts's Law deceleration)</li> <li>PD correction (steer toward target/arc)</li> <li>Correlated noise (hand tremor)</li> <li>Stabilization (damping + smoothing)</li> <li>Step limiting (prevent jumps and backtracking)</li> </ol> <p>Attributes:</p> Name Type Description <code>R_screen</code> <code>Optional[ndarray]</code> <p>Rotation matrix for unit\u2192screen conversion.</p> <code>R_unit</code> <code>Optional[ndarray]</code> <p>Rotation matrix for screen\u2192unit conversion (R_screen.T).</p> <code>D</code> <code>float</code> <p>Distance between start and target in screen pixels.</p> <code>origin</code> <code>Optional[ndarray]</code> <p>Start point in screen coordinates.</p> Example <p>gen = PDPathGenerator() path, progress, steps, params = gen.generate_path( ...     start_x=100, start_y=200, ...     end_x=500, end_y=400, ...     speed=0.35, ...     noise=0.2, ...     arc_strength=0.15 ... ) len(path)  # Number of points in path 47</p> Source code in <code>src/pathgenerator/generator.py</code> <pre><code>class PDPathGenerator:\n    \"\"\"Human-like mouse path generator using PD control.\n\n    Uses a standard unit-frame approach for resolution-independent path generation:\n\n    1. Transform the problem so start=(0,0) and target=(1,0)\n    2. Simulate movement with feedforward velocity and PD correction (inlined for performance)\n    3. Apply human-like noise, stabilization, and velocity profiles\n    4. Transform back to screen coordinates\n\n    The physics simulation loop integrates several behaviors:\n\n    1. Feedforward + braking (Fitts's Law deceleration)\n    2. PD correction (steer toward target/arc)\n    3. Correlated noise (hand tremor)\n    4. Stabilization (damping + smoothing)\n    5. Step limiting (prevent jumps and backtracking)\n\n    Attributes:\n        R_screen: Rotation matrix for unit\u2192screen conversion.\n        R_unit: Rotation matrix for screen\u2192unit conversion (R_screen.T).\n        D: Distance between start and target in screen pixels.\n        origin: Start point in screen coordinates.\n\n    Example:\n        &gt;&gt;&gt; gen = PDPathGenerator()\n        &gt;&gt;&gt; path, progress, steps, params = gen.generate_path(\n        ...     start_x=100, start_y=200,\n        ...     end_x=500, end_y=400,\n        ...     speed=0.35,\n        ...     noise=0.2,\n        ...     arc_strength=0.15\n        ... )\n        &gt;&gt;&gt; len(path)  # Number of points in path\n        47\n    \"\"\"\n\n    # Keys that are loaded from preset files\n    PRESET_KEYS = (\n        'mouse_velocity', 'kp_start', 'kp_end', 'stabilization', 'noise',\n        'keep_prob_start', 'keep_prob_end', 'arc_strength', 'variance',\n        'overshoot_prob'\n    )\n\n    # Default values for preset parameters\n    DEFAULT_PRESET = {\n        'mouse_velocity': 0.65,\n        'kp_start': 0.01,\n        'kp_end': 0.01,\n        'stabilization': 0.15,\n        'noise': 0.0,\n        'keep_prob_start': 0.70,\n        'keep_prob_end': 0.98,\n        'arc_strength': 0.0,\n        'variance': 0.0,\n        'overshoot_prob': 0.0\n    }\n\n    def __init__(self, preset_file: Optional[str] = None):\n        \"\"\"Initialize the path generator.\n\n        Args:\n            preset_file: Optional path to a JSON file with preset parameters.\n                         If provided, these values become the defaults for generate_path().\n\n        Example:\n            &gt;&gt;&gt; gen = PDPathGenerator('natural.json')\n            &gt;&gt;&gt; path, *_ = gen.generate_path(100, 200, 500, 400)  # Uses preset values\n        \"\"\"\n        self.R_screen: Optional[np.ndarray] = None\n        self.R_unit: Optional[np.ndarray] = None\n        self.D: float = 0.0\n        self.origin: Optional[np.ndarray] = None\n\n        # Load preset or use defaults\n        if preset_file is not None:\n            self.preset = self._load_preset_file(preset_file)\n        else:\n            self.preset = self.DEFAULT_PRESET.copy()\n\n    @staticmethod\n    def _load_preset_file(filepath: str) -&gt; dict:\n        \"\"\"Load parameter preset from a JSON file.\n\n        Args:\n            filepath: Path to the JSON file.\n\n        Returns:\n            Dictionary of parameter values merged with defaults.\n        \"\"\"\n        import json\n\n        preset = PDPathGenerator.DEFAULT_PRESET.copy()\n\n        with open(filepath, 'r') as f:\n            data = json.load(f)\n\n        # Validate keys\n        supported = set(PDPathGenerator.PRESET_KEYS)\n        unknown = set(data.keys()) - supported\n        if unknown:\n            raise ValueError(f\"Unknown parameters in preset file: {unknown}. Supported: {supported}\")\n\n        # Only load recognized keys (safety reduntant but keeps logic clean)\n        for key in PDPathGenerator.PRESET_KEYS:\n            if key in data:\n                preset[key] = data[key]\n\n        return preset\n\n    # -------------------- Parameter Randomization --------------------\n\n    @staticmethod\n    def _randomize(params: dict, pct: float = 0.10) -&gt; dict:\n        \"\"\"Apply random jitter to parameter values.\n\n        Args:\n            params: Dictionary of parameter names to values.\n            pct: Maximum percentage variation (0.10 = \u00b110%).\n\n        Returns:\n            New dictionary with jittered values.\n\n        Example:\n            &gt;&gt;&gt; jittered = PDPathGenerator._randomize({'x': 10.0, 'mouse_velocity': 0.35}, pct=0.1)\n            &gt;&gt;&gt; 9.0 &lt;= jittered['x'] &lt;= 11.0\n            True\n            &gt;&gt;&gt; 0.315 &lt;= jittered['mouse_velocity'] &lt;= 0.385  # \u00b110% of 0.35\n            True\n        \"\"\"\n        out = {}\n        for k, v in params.items():\n            jitter = 1.0 + random.uniform(-pct, pct)\n            out[k] = v * jitter\n        return out\n\n    # -------------------- Coordinate Transforms --------------------\n\n    def _setup_transforms(self, start: np.ndarray, target: np.ndarray) -&gt; None:\n            # 1. Get the transform that aligns Screen -&gt; Unit (flattens the line)\n            R_align, self.D = get_unit_transform(start, target)\n\n            # 2. Store it as R_unit\n            self.R_unit = R_align\n\n            # 3. The inverse (Transpose) rotates Unit -&gt; Screen (lifts the line)\n            self.R_screen = R_align.T\n\n            self.origin = start\n\n    def _unit_to_screen(self, Pu: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Convert unit-frame point to screen coordinates.\n\n        Args:\n            Pu: Point in unit frame as [x, y] array.\n\n        Returns:\n            Point in screen coordinates as float32 array.\n        \"\"\"\n        return (self.origin + (Pu * self.D) @ self.R_screen).astype(np.float32)\n\n    def _screen_to_unit(self, Ps: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Convert screen point to unit-frame.\n\n        Args:\n            Ps: Point in screen coordinates as [x, y] array.\n\n        Returns:\n            Point in unit frame as float32 array.\n        \"\"\"\n        return ((Ps - self.origin) @ self.R_unit / max(self.D, 1e-6)).astype(np.float32)\n\n    # -------------------- Velocity Transformations --------------------\n\n    # _init_velocity and _compute_kp_blend removed (logic inlined in generate_path)\n\n    # -------------------- Path Post-Processing --------------------\n\n    def _apply_overshoot(\n        self,\n        path: np.ndarray,\n        end_x: float,\n        end_y: float,\n        knobs: dict\n    ) -&gt; np.ndarray:\n        \"\"\"Add overshoot and recovery in screen space.\n\n        Simulates the human tendency to overshoot targets and correct.\n        When triggered, adds points that:\n\n        1. Continue past the target (3-8% of path distance)\n        2. Curve slightly perpendicular to add realism\n        3. Decelerate and recover back to the target\n\n        Args:\n            path: Current path as (N, 2) numpy array.\n            end_x: Target X coordinate.\n            end_y: Target Y coordinate.\n            knobs: Parameter dictionary with 'overshoot_prob'.\n\n        Returns:\n            Path with overshoot points appended (if triggered).\n        \"\"\"\n        if knobs[\"overshoot_prob\"] &lt;= 0:\n            return path\n\n        if random.random() &gt;= knobs[\"overshoot_prob\"]:\n            return path\n\n        if len(path) &lt; 2:\n            return path\n\n        last_dir = path[-1] - path[-2]\n        last_dir_norm = np.linalg.norm(last_dir)\n\n        if last_dir_norm &lt;= 1e-6:\n            return path\n\n        last_dir = last_dir / last_dir_norm\n\n        perp = np.array([-last_dir[1], last_dir[0]], dtype=np.float32)\n        drift_sign = 1.0 if random.random() &gt; 0.5 else -1.0\n\n        overshoot_dist = self.D * random.uniform(0.03, 0.08)\n        overshoot_steps = max(4, min(int(overshoot_dist / 3), 10))\n\n        overshoot_points = []\n        pos = path[-1].copy()\n\n        for i in range(overshoot_steps):\n            decel = 1.0 - (i / overshoot_steps) * 0.9\n            step_size = (overshoot_dist / overshoot_steps) * decel\n            curve = np.sin((i / overshoot_steps) * np.pi) * 1.5 * drift_sign\n\n            pos = pos + last_dir * step_size + perp * curve\n            overshoot_points.append(pos.copy())\n\n        target_pt = np.array([end_x, end_y], dtype=np.float32)\n        recovery_steps = max(3, overshoot_steps // 2)\n        for i in range(recovery_steps):\n            t = (i + 1) / recovery_steps\n            ease = t * t * (3 - 2 * t)\n            to_target = target_pt - pos\n            pos = pos + to_target * ease * 0.5\n            overshoot_points.append(pos.copy())\n\n        # ensure overshoot_points ends with target_pt    \n        overshoot_points.append(target_pt)\n\n        return np.vstack([path, overshoot_points])\n\n    # -------------------- Knob Preparation --------------------\n\n    def _prepare_knobs(\n        self,\n        mouse_velocity: float,\n        kp_start: float,\n        kp_end: float,\n        stabilization: float,\n        arc_strength: float,\n        noise: float,\n        overshoot_prob: float,\n        keep_prob_start: float,\n        keep_prob_end: float,\n        variance: float,\n        canvas_size: float\n    ) -&gt; dict:\n        \"\"\"Prepare and randomize control knobs for path generation.\n\n        Applies variance-based randomization to most parameters and\n        scales KP values based on path distance.\n\n        Args:\n            mouse_velocity: Base velocity magnitude.\n            kp_start: Correction strength at path start.\n            kp_end: Correction strength near target.\n            stabilization: Smoothing/damping factor.\n            arc_strength: Curvature of arc trajectory.\n            noise: Hand tremor intensity.\n            overshoot_prob: Probability of overshooting target.\n            keep_prob_start: Point density at path start.\n            keep_prob_end: Point density at path end.\n            variance: Random variation percentage for parameters.\n            canvas_size: Larger canvas dimension for KP scaling.\n\n        Returns:\n            Dictionary of prepared parameter values.\n        \"\"\"\n        knobs = self._randomize(\n            dict(\n                mouse_velocity=mouse_velocity,\n                kp_start=kp_start,\n                kp_end=kp_end,\n                stabilization=stabilization,\n                arc_strength=arc_strength,\n                noise=noise,\n                overshoot_prob=overshoot_prob\n            ),\n            pct=max(0.01, variance)\n        )\n\n        knobs['keep_prob_start'] = keep_prob_start\n        knobs['keep_prob_end'] = keep_prob_end\n\n        ref_dist = canvas_size / 4.0\n        kp_scale = np.clip(ref_dist / (self.D + 1e-6), 0.2, 5.0)\n        knobs[\"kp_start\"] *= kp_scale\n        knobs[\"kp_end\"] *= kp_scale\n\n        return knobs\n\n    # -------------------- Main Generation --------------------\n\n    def generate_path(\n        self,\n        start_x: float,\n        start_y: float,\n        end_x: float,\n        end_y: float,\n        canvas_width: int = 1920,\n        canvas_height: int = 1080,\n        *,\n        offset_x: float = 0.0,\n        offset_y: float = 0.0,\n        mouse_velocity: Optional[float] = None,\n        kp_start: Optional[float] = None,\n        kp_end: Optional[float] = None,\n        stabilization: Optional[float] = None,\n        noise: Optional[float] = None,\n        keep_prob_start: Optional[float] = None,\n        keep_prob_end: Optional[float] = None,\n        arc_strength: Optional[float] = None,\n        variance: Optional[float] = None,\n        arc_sign: Optional[float] = None,\n        overshoot_prob: Optional[float] = None,\n        max_steps: int = 1200,\n        tol_px: float = 3.0,\n    ) -&gt; Tuple[np.ndarray, List[float], int, Dict]:\n        \"\"\"Generate a human-like mouse path from start to end.\n\n        This is the main entry point for path generation. It simulates\n        human mouse movement using PD control with various transformations\n        for realism.\n\n        Args:\n            start_x: Starting X coordinate in screen pixels.\n            start_y: Starting Y coordinate in screen pixels.\n            end_x: Target X coordinate in screen pixels.\n            end_y: Target Y coordinate in screen pixels.\n            canvas_width: Canvas/viewport width in pixels.\n            canvas_height: Canvas/viewport height in pixels.\n            offset_x: X offset to add to output coordinates (for window positioning).\n            offset_y: Y offset to add to output coordinates (for window positioning).\n            mouse_velocity: Base velocity (default: from preset).\n            kp_start: Correction strength at start (default: from preset).\n            kp_end: Correction strength near target (default: from preset).\n            stabilization: Smoothing factor (default: from preset).\n            noise: Hand tremor intensity (default: from preset).\n            keep_prob_start: Point density at start (default: from preset).\n            keep_prob_end: Point density at end (default: from preset).\n            arc_strength: Curvature amount (default: from preset).\n            variance: Random parameter variation (default: from preset).\n            arc_sign: Arc direction (+1 or -1), None for random.\n            overshoot_prob: Overshoot probability (default: from preset).\n            max_steps: Maximum simulation steps before termination.\n            tol_px: Distance tolerance for target arrival (pixels).\n\n        Returns:\n            Tuple containing:\n                - path: (N, 2) numpy array of screen coordinates.\n                - progress: List of progress values (0-1) per kept point.\n                - steps: Number of simulation steps executed.\n                - params: Dictionary of actual parameters used (after randomization).\n\n        Example:\n            &gt;&gt;&gt; gen = PDPathGenerator()\n            &gt;&gt;&gt; path, progress, steps, params = gen.generate_path(\n            ...     start_x=100, start_y=200,\n            ...     end_x=500, end_y=400,\n            ...     mouse_velocity=0.35,\n            ...     noise=0.2,\n            ...     arc_strength=0.15\n            ... )\n            &gt;&gt;&gt; path.shape\n            (47, 2)\n            &gt;&gt;&gt; path[0]  # Start point\n            array([100., 200.], dtype=float32)\n            &gt;&gt;&gt; path[-1]  # End point (exact target)\n            array([500., 400.], dtype=float32)\n        \"\"\"\n        start_px = (float(start_x), float(start_y))\n        target_px = (float(end_x), float(end_y))\n        start_vec = np.array(start_px, np.float32)\n        target_vec = np.array(target_px, np.float32)\n\n        self._setup_transforms(start_vec, target_vec)\n\n        # Resolve parameters from arguments or current preset\n        p = self.preset\n        mouse_velocity = mouse_velocity if mouse_velocity is not None else p['mouse_velocity']\n        kp_start = kp_start if kp_start is not None else p['kp_start']\n        kp_end = kp_end if kp_end is not None else p['kp_end']\n        stabilization = stabilization if stabilization is not None else p['stabilization']\n        noise = noise if noise is not None else p['noise']\n        keep_prob_start = keep_prob_start if keep_prob_start is not None else p['keep_prob_start']\n        keep_prob_end = keep_prob_end if keep_prob_end is not None else p['keep_prob_end']\n        arc_strength = arc_strength if arc_strength is not None else p['arc_strength']\n        variance = variance if variance is not None else p['variance']\n        overshoot_prob = overshoot_prob if overshoot_prob is not None else p['overshoot_prob']\n\n        canvas_size = max(canvas_width, canvas_height)\n\n        max_px_step = np.clip(self.D / 30.0, 12.0, 50.0)\n\n        max_step_units = max_px_step / max(self.D, 1e-6)\n\n        knobs = self._prepare_knobs(\n            mouse_velocity, kp_start, kp_end, stabilization, arc_strength,\n            noise, overshoot_prob, keep_prob_start, keep_prob_end,\n            variance, canvas_size\n        )\n\n        SPEED = knobs[\"mouse_velocity\"]\n\n        P_unit = self._screen_to_unit(np.array(start_px, np.float32))\n        vprev_unit = np.array([0.0, 0.0], np.float32)\n        err_sum_unit = np.array([0.0, 0.0], np.float32)\n        noise_state = np.array([0.0, 0.0], dtype=np.float32)\n\n        if arc_sign is None:\n            arc_sign = 1.0 if random.random() &gt; 0.5 else -1.0\n        else:\n            arc_sign = float(arc_sign)\n\n        path: List[Tuple[float, float]] = []\n        prog: List[float] = []\n        start_screen = self._unit_to_screen(P_unit)\n        path.append((float(start_screen[0]), float(start_screen[1])))\n        prog.append(0.0)\n\n        steps = 0\n        last_saved_px = start_screen\n\n        # ---------------------------------------------------------\n        # PERFORMANCE OPTIMIZATION: Inline Physics Loop\n        # ---------------------------------------------------------\n        # Python function calls are expensive. For maximum speed, \n        # we inline the physics logic directly into the main loop.\n        # ---------------------------------------------------------\n\n        # Pre-calculated constants\n        MAX_STEP_M = max_step_units\n        NOISE_STRENGTH = knobs[\"noise\"]\n        STABILIZATION = knobs[\"stabilization\"]\n        KP_START = knobs[\"kp_start\"]\n        KP_END = knobs[\"kp_end\"]\n        ARC_STR = knobs[\"arc_strength\"]\n        OVERSHOOT_PROB = knobs[\"overshoot_prob\"]\n\n        # Keep probability interpolation factors\n        KP_S = knobs[\"keep_prob_start\"]\n        KP_E = knobs[\"keep_prob_end\"]\n\n        # Noise constants\n        SIGMA = NOISE_STRENGTH * 0.002\n        THETA = 0.15\n\n        # PD constants\n        KI = 0.0005\n        PD_GAIN = 20.0\n\n        # Run loop\n        while steps &lt; max_steps:\n            # 1. Update State\n            s = float(np.clip(P_unit[0], 0.0, 1.0))\n\n            if steps == 0:\n                # _init_velocity inline\n                angle_err = random.gauss(0, 0.3)\n                c, s_ang = np.cos(angle_err), np.sin(angle_err)\n                rot = np.array([[c, -s_ang], [s_ang, c]], dtype=np.float32)\n                vprev_unit = rot @ np.array([SPEED, 0.0], dtype=np.float32)\n\n            # 2. Feedforward + Braking (Fitts's Law)\n            current_speed = np.linalg.norm(vprev_unit)\n            if current_speed &lt; 1e-6:\n                direction = np.array([1.0, 0.0], dtype=np.float32)\n            else:\n                direction = vprev_unit / current_speed\n\n            dist_rem = 1.0 - s\n            brake = float(np.clip(dist_rem * 4.0, 0.15, 1.0))\n            v_unit = direction * (SPEED * brake)\n\n            # 3. PD Correction\n            # _compute_kp_blend inline\n            if s &lt; 0.5:\n                weight_far = 1.0 - (s / 0.5)\n                current_kp = weight_far * KP_START\n            else:\n                weight_near = (s - 0.5) / 0.5\n                current_kp = weight_near * KP_END\n\n            current_kp *= brake\n\n            if current_kp &gt; 1e-6:\n                # _compute_arc_offset inline\n                if ARC_STR &gt; 1e-4:\n                    ideal_y = arc_sign * ARC_STR * np.sin(s * np.pi)\n                else:\n                    ideal_y = 0.0\n\n                err_x = 1.0 - P_unit[0]\n                err_y = ideal_y - P_unit[1]\n\n                # Manual array creation is faster than np.array usually, \n                # but we need vector math.\n                # err_unit = np.array([err_x, err_y], np.float32)\n\n                err_sum_unit[0] += err_x\n                err_sum_unit[1] += err_y\n\n                # v_unit = v_unit + current_kp * 20.0 * err_unit + ki * err_sum_unit\n                # Unrolled for speed:\n                v_unit[0] += current_kp * PD_GAIN * err_x + KI * err_sum_unit[0]\n                v_unit[1] += current_kp * PD_GAIN * err_y + KI * err_sum_unit[1]\n\n            # 4. Correlated Noise (Ornstein-Uhlenbeck)\n            if NOISE_STRENGTH &gt; 1e-4:\n                nf = (1.0 - s) ** 1.3\n\n                # Random kick\n                r1 = random.gauss(0, 1)\n                r2 = random.gauss(0, 1)\n\n                # Update noise state: noise_state = noise_state - theta*noise_state + sigma*kick\n                ns_x = noise_state[0]\n                ns_y = noise_state[1]\n\n                noise_state[0] = ns_x + (-THETA * ns_x) + (SIGMA * r1)\n                noise_state[1] = ns_y + (-THETA * ns_y) + (SIGMA * r2)\n\n                v_unit[0] += noise_state[0] * nf\n                v_unit[1] += noise_state[1] * nf\n\n            # 5. Stabilization\n            damp_val = STABILIZATION * 0.5\n            if damp_val &gt; 1e-6:\n                # v_unit = v_unit - damp_val * (v_unit - vprev_unit)\n                v_unit[0] -= damp_val * (v_unit[0] - vprev_unit[0])\n                v_unit[1] -= damp_val * (v_unit[1] - vprev_unit[1])\n\n            alpha = max(0.01, 1.0 - STABILIZATION)\n            # v_unit = alpha * v_unit + (1.0 - alpha) * vprev_unit\n            v_unit[0] = alpha * v_unit[0] + (1.0 - alpha) * vprev_unit[0]\n            v_unit[1] = alpha * v_unit[1] + (1.0 - alpha) * vprev_unit[1]\n\n            # 6. Limit Step\n            mag = float(np.hypot(v_unit[0], v_unit[1])) + 1e-8\n            step_limit = MAX_STEP_M * (0.5 + 0.5 * (1.0 - s) ** 1.5)\n            if mag &gt; step_limit:\n                scale = step_limit / mag\n                v_unit[0] *= scale\n                v_unit[1] *= scale\n\n            max_forward = max(0.0, 1.0 - P_unit[0])\n            if v_unit[0] &gt; max_forward:\n                v_unit[0] = max_forward\n\n            # 7. Integrate\n            # P_next = P_unit + v_unit\n            pn_x = P_unit[0] + v_unit[0]\n            pn_y = P_unit[1] + v_unit[1]\n\n            # Clip X\n            if pn_x &gt; 1.0: pn_x = 1.0\n            elif pn_x &lt; -0.05: pn_x = -0.05\n\n            # Calculate screen pos manually to avoid function call overhead\n            # P_screen = origin + (Pu * D) @ R_screen\n            # This matrix mul is unavoidable but expensive.\n            # R_screen is 2x2.\n            # Let's perform the transform inline.\n            # P_unit_scaled = (pn_x * D, pn_y * D)\n            pus_x = pn_x * self.D\n            pus_y = pn_y * self.D\n\n            # rot is (2,2)\n            # res = [pus_x*R00 + pus_y*R10, pus_x*R01 + pus_y*R11] + origin\n\n            new_px_x = self.origin[0] + (pus_x * self.R_screen[0,0] + pus_y * self.R_screen[1,0])\n            new_px_y = self.origin[1] + (pus_x * self.R_screen[0,1] + pus_y * self.R_screen[1,1])\n\n            # Update P_unit (for next iteration, usually just P_next unless we clamped/transformed back)\n            # Since we just clipped pn_x, we can use that directly for the loop state\n            P_unit[0] = pn_x\n            P_unit[1] = pn_y\n\n            vprev_unit[0] = v_unit[0]\n            vprev_unit[1] = v_unit[1]\n\n            # 8. Store Point\n            keep_p = KP_S + (KP_E - KP_S) * s\n\n            should_keep = random.random() &lt; keep_p or s &gt;= 0.97\n\n            if should_keep:\n                path.append((float(new_px_x), float(new_px_y)))\n                prog.append(s)\n                last_saved_px[0] = new_px_x\n                last_saved_px[1] = new_px_y\n\n            # Check termination\n            # dist_target = hypot(target - new)\n            dtx = target_px[0] - new_px_x\n            dty = target_px[1] - new_px_y\n            if (dtx*dtx + dty*dty) &lt;= (tol_px * tol_px) or s &gt;= 0.995:\n                break\n\n            steps += 1\n\n        path_array = np.array(path, dtype=np.float32)\n\n        path_fixed = rotate_scale_path_to_hit_target(\n            path_array, (start_x, start_y), (end_x, end_y), scale_to_distance=True\n        )\n\n        path_fixed = self._apply_overshoot(path_fixed, end_x, end_y, knobs)\n\n        # Apply viewport offset if specified\n        if offset_x != 0.0 or offset_y != 0.0:\n            path_fixed = path_fixed + np.array([offset_x, offset_y], dtype=np.float32)\n\n        return path_fixed, prog, steps, knobs\n</code></pre>"},{"location":"api/generator/#pathgenerator.generator.PDPathGenerator.__init__","title":"<code>__init__(preset_file=None)</code>","text":"<p>Initialize the path generator.</p> <p>Parameters:</p> Name Type Description Default <code>preset_file</code> <code>Optional[str]</code> <p>Optional path to a JSON file with preset parameters.          If provided, these values become the defaults for generate_path().</p> <code>None</code> Example <p>gen = PDPathGenerator('natural.json') path, *_ = gen.generate_path(100, 200, 500, 400)  # Uses preset values</p> Source code in <code>src/pathgenerator/generator.py</code> <pre><code>def __init__(self, preset_file: Optional[str] = None):\n    \"\"\"Initialize the path generator.\n\n    Args:\n        preset_file: Optional path to a JSON file with preset parameters.\n                     If provided, these values become the defaults for generate_path().\n\n    Example:\n        &gt;&gt;&gt; gen = PDPathGenerator('natural.json')\n        &gt;&gt;&gt; path, *_ = gen.generate_path(100, 200, 500, 400)  # Uses preset values\n    \"\"\"\n    self.R_screen: Optional[np.ndarray] = None\n    self.R_unit: Optional[np.ndarray] = None\n    self.D: float = 0.0\n    self.origin: Optional[np.ndarray] = None\n\n    # Load preset or use defaults\n    if preset_file is not None:\n        self.preset = self._load_preset_file(preset_file)\n    else:\n        self.preset = self.DEFAULT_PRESET.copy()\n</code></pre>"},{"location":"api/generator/#pathgenerator.generator.PDPathGenerator.generate_path","title":"<code>generate_path(start_x, start_y, end_x, end_y, canvas_width=1920, canvas_height=1080, *, offset_x=0.0, offset_y=0.0, mouse_velocity=None, kp_start=None, kp_end=None, stabilization=None, noise=None, keep_prob_start=None, keep_prob_end=None, arc_strength=None, variance=None, arc_sign=None, overshoot_prob=None, max_steps=1200, tol_px=3.0)</code>","text":"<p>Generate a human-like mouse path from start to end.</p> <p>This is the main entry point for path generation. It simulates human mouse movement using PD control with various transformations for realism.</p> <p>Parameters:</p> Name Type Description Default <code>start_x</code> <code>float</code> <p>Starting X coordinate in screen pixels.</p> required <code>start_y</code> <code>float</code> <p>Starting Y coordinate in screen pixels.</p> required <code>end_x</code> <code>float</code> <p>Target X coordinate in screen pixels.</p> required <code>end_y</code> <code>float</code> <p>Target Y coordinate in screen pixels.</p> required <code>canvas_width</code> <code>int</code> <p>Canvas/viewport width in pixels.</p> <code>1920</code> <code>canvas_height</code> <code>int</code> <p>Canvas/viewport height in pixels.</p> <code>1080</code> <code>offset_x</code> <code>float</code> <p>X offset to add to output coordinates (for window positioning).</p> <code>0.0</code> <code>offset_y</code> <code>float</code> <p>Y offset to add to output coordinates (for window positioning).</p> <code>0.0</code> <code>mouse_velocity</code> <code>Optional[float]</code> <p>Base velocity (default: from preset).</p> <code>None</code> <code>kp_start</code> <code>Optional[float]</code> <p>Correction strength at start (default: from preset).</p> <code>None</code> <code>kp_end</code> <code>Optional[float]</code> <p>Correction strength near target (default: from preset).</p> <code>None</code> <code>stabilization</code> <code>Optional[float]</code> <p>Smoothing factor (default: from preset).</p> <code>None</code> <code>noise</code> <code>Optional[float]</code> <p>Hand tremor intensity (default: from preset).</p> <code>None</code> <code>keep_prob_start</code> <code>Optional[float]</code> <p>Point density at start (default: from preset).</p> <code>None</code> <code>keep_prob_end</code> <code>Optional[float]</code> <p>Point density at end (default: from preset).</p> <code>None</code> <code>arc_strength</code> <code>Optional[float]</code> <p>Curvature amount (default: from preset).</p> <code>None</code> <code>variance</code> <code>Optional[float]</code> <p>Random parameter variation (default: from preset).</p> <code>None</code> <code>arc_sign</code> <code>Optional[float]</code> <p>Arc direction (+1 or -1), None for random.</p> <code>None</code> <code>overshoot_prob</code> <code>Optional[float]</code> <p>Overshoot probability (default: from preset).</p> <code>None</code> <code>max_steps</code> <code>int</code> <p>Maximum simulation steps before termination.</p> <code>1200</code> <code>tol_px</code> <code>float</code> <p>Distance tolerance for target arrival (pixels).</p> <code>3.0</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, List[float], int, Dict]</code> <p>Tuple containing: - path: (N, 2) numpy array of screen coordinates. - progress: List of progress values (0-1) per kept point. - steps: Number of simulation steps executed. - params: Dictionary of actual parameters used (after randomization).</p> Example <p>gen = PDPathGenerator() path, progress, steps, params = gen.generate_path( ...     start_x=100, start_y=200, ...     end_x=500, end_y=400, ...     mouse_velocity=0.35, ...     noise=0.2, ...     arc_strength=0.15 ... ) path.shape (47, 2) path[0]  # Start point array([100., 200.], dtype=float32) path[-1]  # End point (exact target) array([500., 400.], dtype=float32)</p> Source code in <code>src/pathgenerator/generator.py</code> <pre><code>def generate_path(\n    self,\n    start_x: float,\n    start_y: float,\n    end_x: float,\n    end_y: float,\n    canvas_width: int = 1920,\n    canvas_height: int = 1080,\n    *,\n    offset_x: float = 0.0,\n    offset_y: float = 0.0,\n    mouse_velocity: Optional[float] = None,\n    kp_start: Optional[float] = None,\n    kp_end: Optional[float] = None,\n    stabilization: Optional[float] = None,\n    noise: Optional[float] = None,\n    keep_prob_start: Optional[float] = None,\n    keep_prob_end: Optional[float] = None,\n    arc_strength: Optional[float] = None,\n    variance: Optional[float] = None,\n    arc_sign: Optional[float] = None,\n    overshoot_prob: Optional[float] = None,\n    max_steps: int = 1200,\n    tol_px: float = 3.0,\n) -&gt; Tuple[np.ndarray, List[float], int, Dict]:\n    \"\"\"Generate a human-like mouse path from start to end.\n\n    This is the main entry point for path generation. It simulates\n    human mouse movement using PD control with various transformations\n    for realism.\n\n    Args:\n        start_x: Starting X coordinate in screen pixels.\n        start_y: Starting Y coordinate in screen pixels.\n        end_x: Target X coordinate in screen pixels.\n        end_y: Target Y coordinate in screen pixels.\n        canvas_width: Canvas/viewport width in pixels.\n        canvas_height: Canvas/viewport height in pixels.\n        offset_x: X offset to add to output coordinates (for window positioning).\n        offset_y: Y offset to add to output coordinates (for window positioning).\n        mouse_velocity: Base velocity (default: from preset).\n        kp_start: Correction strength at start (default: from preset).\n        kp_end: Correction strength near target (default: from preset).\n        stabilization: Smoothing factor (default: from preset).\n        noise: Hand tremor intensity (default: from preset).\n        keep_prob_start: Point density at start (default: from preset).\n        keep_prob_end: Point density at end (default: from preset).\n        arc_strength: Curvature amount (default: from preset).\n        variance: Random parameter variation (default: from preset).\n        arc_sign: Arc direction (+1 or -1), None for random.\n        overshoot_prob: Overshoot probability (default: from preset).\n        max_steps: Maximum simulation steps before termination.\n        tol_px: Distance tolerance for target arrival (pixels).\n\n    Returns:\n        Tuple containing:\n            - path: (N, 2) numpy array of screen coordinates.\n            - progress: List of progress values (0-1) per kept point.\n            - steps: Number of simulation steps executed.\n            - params: Dictionary of actual parameters used (after randomization).\n\n    Example:\n        &gt;&gt;&gt; gen = PDPathGenerator()\n        &gt;&gt;&gt; path, progress, steps, params = gen.generate_path(\n        ...     start_x=100, start_y=200,\n        ...     end_x=500, end_y=400,\n        ...     mouse_velocity=0.35,\n        ...     noise=0.2,\n        ...     arc_strength=0.15\n        ... )\n        &gt;&gt;&gt; path.shape\n        (47, 2)\n        &gt;&gt;&gt; path[0]  # Start point\n        array([100., 200.], dtype=float32)\n        &gt;&gt;&gt; path[-1]  # End point (exact target)\n        array([500., 400.], dtype=float32)\n    \"\"\"\n    start_px = (float(start_x), float(start_y))\n    target_px = (float(end_x), float(end_y))\n    start_vec = np.array(start_px, np.float32)\n    target_vec = np.array(target_px, np.float32)\n\n    self._setup_transforms(start_vec, target_vec)\n\n    # Resolve parameters from arguments or current preset\n    p = self.preset\n    mouse_velocity = mouse_velocity if mouse_velocity is not None else p['mouse_velocity']\n    kp_start = kp_start if kp_start is not None else p['kp_start']\n    kp_end = kp_end if kp_end is not None else p['kp_end']\n    stabilization = stabilization if stabilization is not None else p['stabilization']\n    noise = noise if noise is not None else p['noise']\n    keep_prob_start = keep_prob_start if keep_prob_start is not None else p['keep_prob_start']\n    keep_prob_end = keep_prob_end if keep_prob_end is not None else p['keep_prob_end']\n    arc_strength = arc_strength if arc_strength is not None else p['arc_strength']\n    variance = variance if variance is not None else p['variance']\n    overshoot_prob = overshoot_prob if overshoot_prob is not None else p['overshoot_prob']\n\n    canvas_size = max(canvas_width, canvas_height)\n\n    max_px_step = np.clip(self.D / 30.0, 12.0, 50.0)\n\n    max_step_units = max_px_step / max(self.D, 1e-6)\n\n    knobs = self._prepare_knobs(\n        mouse_velocity, kp_start, kp_end, stabilization, arc_strength,\n        noise, overshoot_prob, keep_prob_start, keep_prob_end,\n        variance, canvas_size\n    )\n\n    SPEED = knobs[\"mouse_velocity\"]\n\n    P_unit = self._screen_to_unit(np.array(start_px, np.float32))\n    vprev_unit = np.array([0.0, 0.0], np.float32)\n    err_sum_unit = np.array([0.0, 0.0], np.float32)\n    noise_state = np.array([0.0, 0.0], dtype=np.float32)\n\n    if arc_sign is None:\n        arc_sign = 1.0 if random.random() &gt; 0.5 else -1.0\n    else:\n        arc_sign = float(arc_sign)\n\n    path: List[Tuple[float, float]] = []\n    prog: List[float] = []\n    start_screen = self._unit_to_screen(P_unit)\n    path.append((float(start_screen[0]), float(start_screen[1])))\n    prog.append(0.0)\n\n    steps = 0\n    last_saved_px = start_screen\n\n    # ---------------------------------------------------------\n    # PERFORMANCE OPTIMIZATION: Inline Physics Loop\n    # ---------------------------------------------------------\n    # Python function calls are expensive. For maximum speed, \n    # we inline the physics logic directly into the main loop.\n    # ---------------------------------------------------------\n\n    # Pre-calculated constants\n    MAX_STEP_M = max_step_units\n    NOISE_STRENGTH = knobs[\"noise\"]\n    STABILIZATION = knobs[\"stabilization\"]\n    KP_START = knobs[\"kp_start\"]\n    KP_END = knobs[\"kp_end\"]\n    ARC_STR = knobs[\"arc_strength\"]\n    OVERSHOOT_PROB = knobs[\"overshoot_prob\"]\n\n    # Keep probability interpolation factors\n    KP_S = knobs[\"keep_prob_start\"]\n    KP_E = knobs[\"keep_prob_end\"]\n\n    # Noise constants\n    SIGMA = NOISE_STRENGTH * 0.002\n    THETA = 0.15\n\n    # PD constants\n    KI = 0.0005\n    PD_GAIN = 20.0\n\n    # Run loop\n    while steps &lt; max_steps:\n        # 1. Update State\n        s = float(np.clip(P_unit[0], 0.0, 1.0))\n\n        if steps == 0:\n            # _init_velocity inline\n            angle_err = random.gauss(0, 0.3)\n            c, s_ang = np.cos(angle_err), np.sin(angle_err)\n            rot = np.array([[c, -s_ang], [s_ang, c]], dtype=np.float32)\n            vprev_unit = rot @ np.array([SPEED, 0.0], dtype=np.float32)\n\n        # 2. Feedforward + Braking (Fitts's Law)\n        current_speed = np.linalg.norm(vprev_unit)\n        if current_speed &lt; 1e-6:\n            direction = np.array([1.0, 0.0], dtype=np.float32)\n        else:\n            direction = vprev_unit / current_speed\n\n        dist_rem = 1.0 - s\n        brake = float(np.clip(dist_rem * 4.0, 0.15, 1.0))\n        v_unit = direction * (SPEED * brake)\n\n        # 3. PD Correction\n        # _compute_kp_blend inline\n        if s &lt; 0.5:\n            weight_far = 1.0 - (s / 0.5)\n            current_kp = weight_far * KP_START\n        else:\n            weight_near = (s - 0.5) / 0.5\n            current_kp = weight_near * KP_END\n\n        current_kp *= brake\n\n        if current_kp &gt; 1e-6:\n            # _compute_arc_offset inline\n            if ARC_STR &gt; 1e-4:\n                ideal_y = arc_sign * ARC_STR * np.sin(s * np.pi)\n            else:\n                ideal_y = 0.0\n\n            err_x = 1.0 - P_unit[0]\n            err_y = ideal_y - P_unit[1]\n\n            # Manual array creation is faster than np.array usually, \n            # but we need vector math.\n            # err_unit = np.array([err_x, err_y], np.float32)\n\n            err_sum_unit[0] += err_x\n            err_sum_unit[1] += err_y\n\n            # v_unit = v_unit + current_kp * 20.0 * err_unit + ki * err_sum_unit\n            # Unrolled for speed:\n            v_unit[0] += current_kp * PD_GAIN * err_x + KI * err_sum_unit[0]\n            v_unit[1] += current_kp * PD_GAIN * err_y + KI * err_sum_unit[1]\n\n        # 4. Correlated Noise (Ornstein-Uhlenbeck)\n        if NOISE_STRENGTH &gt; 1e-4:\n            nf = (1.0 - s) ** 1.3\n\n            # Random kick\n            r1 = random.gauss(0, 1)\n            r2 = random.gauss(0, 1)\n\n            # Update noise state: noise_state = noise_state - theta*noise_state + sigma*kick\n            ns_x = noise_state[0]\n            ns_y = noise_state[1]\n\n            noise_state[0] = ns_x + (-THETA * ns_x) + (SIGMA * r1)\n            noise_state[1] = ns_y + (-THETA * ns_y) + (SIGMA * r2)\n\n            v_unit[0] += noise_state[0] * nf\n            v_unit[1] += noise_state[1] * nf\n\n        # 5. Stabilization\n        damp_val = STABILIZATION * 0.5\n        if damp_val &gt; 1e-6:\n            # v_unit = v_unit - damp_val * (v_unit - vprev_unit)\n            v_unit[0] -= damp_val * (v_unit[0] - vprev_unit[0])\n            v_unit[1] -= damp_val * (v_unit[1] - vprev_unit[1])\n\n        alpha = max(0.01, 1.0 - STABILIZATION)\n        # v_unit = alpha * v_unit + (1.0 - alpha) * vprev_unit\n        v_unit[0] = alpha * v_unit[0] + (1.0 - alpha) * vprev_unit[0]\n        v_unit[1] = alpha * v_unit[1] + (1.0 - alpha) * vprev_unit[1]\n\n        # 6. Limit Step\n        mag = float(np.hypot(v_unit[0], v_unit[1])) + 1e-8\n        step_limit = MAX_STEP_M * (0.5 + 0.5 * (1.0 - s) ** 1.5)\n        if mag &gt; step_limit:\n            scale = step_limit / mag\n            v_unit[0] *= scale\n            v_unit[1] *= scale\n\n        max_forward = max(0.0, 1.0 - P_unit[0])\n        if v_unit[0] &gt; max_forward:\n            v_unit[0] = max_forward\n\n        # 7. Integrate\n        # P_next = P_unit + v_unit\n        pn_x = P_unit[0] + v_unit[0]\n        pn_y = P_unit[1] + v_unit[1]\n\n        # Clip X\n        if pn_x &gt; 1.0: pn_x = 1.0\n        elif pn_x &lt; -0.05: pn_x = -0.05\n\n        # Calculate screen pos manually to avoid function call overhead\n        # P_screen = origin + (Pu * D) @ R_screen\n        # This matrix mul is unavoidable but expensive.\n        # R_screen is 2x2.\n        # Let's perform the transform inline.\n        # P_unit_scaled = (pn_x * D, pn_y * D)\n        pus_x = pn_x * self.D\n        pus_y = pn_y * self.D\n\n        # rot is (2,2)\n        # res = [pus_x*R00 + pus_y*R10, pus_x*R01 + pus_y*R11] + origin\n\n        new_px_x = self.origin[0] + (pus_x * self.R_screen[0,0] + pus_y * self.R_screen[1,0])\n        new_px_y = self.origin[1] + (pus_x * self.R_screen[0,1] + pus_y * self.R_screen[1,1])\n\n        # Update P_unit (for next iteration, usually just P_next unless we clamped/transformed back)\n        # Since we just clipped pn_x, we can use that directly for the loop state\n        P_unit[0] = pn_x\n        P_unit[1] = pn_y\n\n        vprev_unit[0] = v_unit[0]\n        vprev_unit[1] = v_unit[1]\n\n        # 8. Store Point\n        keep_p = KP_S + (KP_E - KP_S) * s\n\n        should_keep = random.random() &lt; keep_p or s &gt;= 0.97\n\n        if should_keep:\n            path.append((float(new_px_x), float(new_px_y)))\n            prog.append(s)\n            last_saved_px[0] = new_px_x\n            last_saved_px[1] = new_px_y\n\n        # Check termination\n        # dist_target = hypot(target - new)\n        dtx = target_px[0] - new_px_x\n        dty = target_px[1] - new_px_y\n        if (dtx*dtx + dty*dty) &lt;= (tol_px * tol_px) or s &gt;= 0.995:\n            break\n\n        steps += 1\n\n    path_array = np.array(path, dtype=np.float32)\n\n    path_fixed = rotate_scale_path_to_hit_target(\n        path_array, (start_x, start_y), (end_x, end_y), scale_to_distance=True\n    )\n\n    path_fixed = self._apply_overshoot(path_fixed, end_x, end_y, knobs)\n\n    # Apply viewport offset if specified\n    if offset_x != 0.0 or offset_y != 0.0:\n        path_fixed = path_fixed + np.array([offset_x, offset_y], dtype=np.float32)\n\n    return path_fixed, prog, steps, knobs\n</code></pre>"},{"location":"api/geometry/","title":"Geometry Module","text":"<p>Coordinate transformation utilities for the path generator.</p>"},{"location":"api/geometry/#pathgenerator.geometry","title":"<code>geometry</code>","text":"<p>Coordinate transformation utilities for the path generator.</p> <p>This module provides functions for transforming coordinates between screen space and a normalized \"unit frame\" where path generation is resolution-independent.</p> <p>The unit frame transforms any start\u2192target pair such that: - Start point becomes (0, 0) - Target point becomes (1, 0) - All distances are normalized relative to the start-target distance</p>"},{"location":"api/geometry/#pathgenerator.geometry.get_unit_transform","title":"<code>get_unit_transform(start, target)</code>","text":"<p>Compute the rotation matrix and distance for unit-frame transformation.</p> <p>Calculates the transform needed to map screen coordinates to a normalized unit frame where start=(0,0) and target=(1,0).</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>ndarray</code> <p>Starting point as (x, y) array in screen coordinates.</p> required <code>target</code> <code>ndarray</code> <p>Target point as (x, y) array in screen coordinates.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, float]</code> <p>Tuple containing: - R: 2x2 rotation matrix that aligns the start\u2192target vector with +X axis. - D: Distance between start and target (used for scaling).</p> Example <p>start = np.array([100, 200]) target = np.array([300, 200]) R, D = get_unit_transform(start, target) D 200.0</p> Note <p>To convert screen \u2192 unit: <code>P_unit = (P_screen - start) @ R.T / D</code> To convert unit \u2192 screen: <code>P_screen = start + (P_unit * D) @ R</code></p> Source code in <code>src/pathgenerator/geometry.py</code> <pre><code>def get_unit_transform(\n    start: np.ndarray, \n    target: np.ndarray\n) -&gt; Tuple[np.ndarray, float]:\n    \"\"\"Compute the rotation matrix and distance for unit-frame transformation.\n\n    Calculates the transform needed to map screen coordinates to a normalized\n    unit frame where start=(0,0) and target=(1,0).\n\n    Args:\n        start: Starting point as (x, y) array in screen coordinates.\n        target: Target point as (x, y) array in screen coordinates.\n\n    Returns:\n        Tuple containing:\n            - R: 2x2 rotation matrix that aligns the start\u2192target vector with +X axis.\n            - D: Distance between start and target (used for scaling).\n\n    Example:\n        &gt;&gt;&gt; start = np.array([100, 200])\n        &gt;&gt;&gt; target = np.array([300, 200])\n        &gt;&gt;&gt; R, D = get_unit_transform(start, target)\n        &gt;&gt;&gt; D\n        200.0\n        &gt;&gt;&gt; # R is identity since target is already along +X from start\n\n    Note:\n        To convert screen \u2192 unit: `P_unit = (P_screen - start) @ R.T / D`\n        To convert unit \u2192 screen: `P_screen = start + (P_unit * D) @ R`\n    \"\"\"\n    sx, sy = start\n    tx, ty = target\n    v = np.array([tx - sx, ty - sy], dtype=np.float32)\n    D = float(np.hypot(v[0], v[1])) or 1.0\n    v /= D\n    c, s = v[0], v[1]\n    # Rotate by -theta (align vector to x-axis)\n    # Applied as: [x, y] @ R.T = [c*x + s*y, -s*x + c*y]\n    R = np.array([[c, s],\n                  [-s, c]], dtype=np.float32)\n    return R, D\n</code></pre>"},{"location":"api/geometry/#pathgenerator.geometry.get_unit_transform--r-is-identity-since-target-is-already-along-x-from-start","title":"R is identity since target is already along +X from start","text":""},{"location":"api/geometry/#pathgenerator.geometry.rotate_scale_path_to_hit_target","title":"<code>rotate_scale_path_to_hit_target(path_xy, start_xy, target_xy, *, scale_to_distance=True)</code>","text":"<p>Rotate and scale a path so its endpoint exactly matches the target.</p> <p>After path simulation, there may be small numerical errors that cause the final point to not exactly hit the target. This function applies a rotation (and optionally uniform scaling) around the start point to correct this.</p> <p>Parameters:</p> Name Type Description Default <code>path_xy</code> <code>ndarray</code> <p>Path as (N, 2) numpy array of screen coordinates.</p> required <code>start_xy</code> <code>Tuple[float, float]</code> <p>Start point (should match path_xy[0]).</p> required <code>target_xy</code> <code>Tuple[float, float]</code> <p>Desired endpoint for the path.</p> required <code>scale_to_distance</code> <code>bool</code> <p>If True, uniformly scale the path so the endpoint distance matches exactly. If False, only rotate (preserves path length).</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Transformed path as (N, 2) numpy array with path[-1] == target_xy.</p> Example <p>path = np.array([[0, 0], [50, 10], [95, 5]])  # Slightly off-target target = (100, 0) fixed = rotate_scale_path_to_hit_target(path, (0, 0), target) fixed[-1] array([100., 0.])</p> Note <p>If either the current endpoint or target is very close to the start (&lt; 1e-6 distance), the path is returned unchanged to avoid division by zero.</p> Source code in <code>src/pathgenerator/geometry.py</code> <pre><code>def rotate_scale_path_to_hit_target(\n    path_xy: np.ndarray, \n    start_xy: Tuple[float, float], \n    target_xy: Tuple[float, float], \n    *, \n    scale_to_distance: bool = True\n) -&gt; np.ndarray:\n    \"\"\"Rotate and scale a path so its endpoint exactly matches the target.\n\n    After path simulation, there may be small numerical errors that cause the\n    final point to not exactly hit the target. This function applies a rotation\n    (and optionally uniform scaling) around the start point to correct this.\n\n    Args:\n        path_xy: Path as (N, 2) numpy array of screen coordinates.\n        start_xy: Start point (should match path_xy[0]).\n        target_xy: Desired endpoint for the path.\n        scale_to_distance: If True, uniformly scale the path so the endpoint\n            distance matches exactly. If False, only rotate (preserves path length).\n\n    Returns:\n        Transformed path as (N, 2) numpy array with path[-1] == target_xy.\n\n    Example:\n        &gt;&gt;&gt; path = np.array([[0, 0], [50, 10], [95, 5]])  # Slightly off-target\n        &gt;&gt;&gt; target = (100, 0)\n        &gt;&gt;&gt; fixed = rotate_scale_path_to_hit_target(path, (0, 0), target)\n        &gt;&gt;&gt; fixed[-1]\n        array([100., 0.])\n\n    Note:\n        If either the current endpoint or target is very close to the start\n        (&lt; 1e-6 distance), the path is returned unchanged to avoid division\n        by zero.\n    \"\"\"\n    P0 = np.asarray(start_xy,  dtype=np.float32)\n    PT = np.asarray(target_xy, dtype=np.float32)\n    P  = np.asarray(path_xy,   dtype=np.float32)\n\n    v1 = P[-1] - P0             # current end vector (from start -&gt; last)\n    v2 = PT   - P0              # desired end vector (from start -&gt; target)\n\n    n1 = np.linalg.norm(v1)\n    n2 = np.linalg.norm(v2)\n    if n1 &lt; 1e-6 or n2 &lt; 1e-6:\n        return P  # degenerate\u2014nothing to do\n\n    # angle to rotate v1 into v2 (signed)\n    dot = float(np.dot(v1, v2))\n    det = float(v1[0]*v2[1] - v1[1]*v2[0])\n    theta = np.arctan2(det, dot)\n\n    c, s = np.cos(theta), np.sin(theta)\n    R = np.array([[c, -s],\n                  [s,  c]], dtype=np.float32)\n\n    # optional uniform scale so magnitudes match (pure rotation if False)\n    scale = (n2 / n1) if scale_to_distance else 1.0\n\n    # rotate+scale about the start point\n    P_centered = P - P0\n    P_new = (P_centered @ R.T) * scale + P0\n\n    # by construction, P_new[-1] == target (up to fp rounding); snap it\n    P_new[-1] = PT\n    return P_new\n</code></pre>"},{"location":"examples/basic_usage/","title":"Basic Usage","text":"<p>This guide covers common usage patterns for the path generator.</p>"},{"location":"examples/basic_usage/#simple-path-generation","title":"Simple Path Generation","text":"<pre><code>from pathgenerator import PDPathGenerator\n\ngen = PDPathGenerator()\n\npath, progress, steps, params = gen.generate_path(\n    start_x=100, start_y=200,\n    end_x=500, end_y=400\n)\n</code></pre>"},{"location":"examples/basic_usage/#return-values","title":"Return Values","text":"Value Type Description <code>path</code> <code>np.ndarray</code> Array of (x, y) coordinates <code>progress</code> <code>List[float]</code> Progress value (0-1) for each point <code>steps</code> <code>int</code> Number of simulation steps <code>params</code> <code>dict</code> Actual parameters used (after randomization)"},{"location":"examples/basic_usage/#moving-the-mouse","title":"Moving the Mouse","text":"<p>To actually move the mouse, pair this with a mouse control library, or (windows only) use the optional <code>PathEmulator</code> included when installing with <code>pip install pathgenerator[windows]</code></p> PathEmulator (Windows)pyautoguipynput <p>Recommended for Windows users for high performance and smooth movement.</p> <pre><code>from pathgenerator import PDPathGenerator, PathEmulator\n\n# Requires: pip install pathgenerator[windows]\nemulator = PathEmulator()\ngen = PDPathGenerator()\n\n# Generate from current mouse position\nstart_x, start_y = emulator.get_position()\npath, *_ = gen.generate_path(start_x, start_y, 500, 400)\n\n# Execute\nemulator.execute_path(path)\n</code></pre> <pre><code>import pyautogui\nimport time\nfrom pathgenerator import PDPathGenerator\n\npyautogui.PAUSE = 0  # Disable default 0.1s pause between actions\n\ngen = PDPathGenerator()\npath, *_ = gen.generate_path(100, 200, 500, 400)\n\nfor x, y in path:\n    pyautogui.moveTo(x, y)\n    time.sleep(0.01)\n</code></pre> <pre><code>from pynput.mouse import Controller\nimport time\nfrom pathgenerator import PDPathGenerator\n\nmouse = Controller()\ngen = PDPathGenerator()\npath, *_ = gen.generate_path(100, 200, 500, 400)\n\nfor x, y in path:\n    mouse.position = (x, y)\n    time.sleep(0.01)\n</code></pre>"},{"location":"examples/basic_usage/#canvas-size","title":"Canvas Size","text":"<p>The generator is resolution-independent, but you can specify your canvas/viewport size for optimal step sizing:</p> <pre><code>path, *_ = gen.generate_path(\n    100, 200, 500, 400,\n    canvas_width=2560,\n    canvas_height=1440\n)\n</code></pre> <p>Default Size</p> <p>The default is 1920x1080. Specifying your actual canvas size helps with step size calculations. The larger dimension is used for scaling.</p>"},{"location":"examples/basic_usage/#windowviewport-targeting","title":"Window/Viewport Targeting","text":"<p>When targeting a specific window on screen, use <code>offset_x</code> and <code>offset_y</code> to translate coordinates:</p> <pre><code># Window at position (200, 100) on screen, size 800x600\n# Move from (50, 50) to (150, 100) within that window\n\npath, *_ = gen.generate_path(\n    50, 50, 150, 100,           # Coordinates relative to window\n    canvas_width=800,           # Window dimensions\n    canvas_height=600,\n    offset_x=200,               # Window's X position on screen\n    offset_y=100                # Window's Y position on screen\n)\n\n# Output path is in screen coordinates: (250, 150) \u2192 (350, 200)\n</code></pre> <p>The offset is applied to all output coordinates, so you can think in window-relative terms while getting screen-ready output.</p>"},{"location":"examples/basic_usage/#using-presets","title":"Using Presets","text":"<p>You can load motion parameters (speed, noise, etc.) from a JSON file:</p> <pre><code>// natural.json\n{\n  \"mouse_velocity\": 0.65,\n  \"kp_start\": 0.0004,\n  \"kp_end\": 0.0004,\n  \"stabilization\": 0.29,\n  \"noise\": 2.6,\n  \"keep_prob_start\": 0.7,\n  \"keep_prob_end\": 0.98,\n  \"arc_strength\": 0.27,\n  \"variance\": 0.45,\n  \"overshoot_prob\": 0.45\n}\n</code></pre> <p>Initialize the generator with the file path:</p> <pre><code>gen = PDPathGenerator('natural.json')\n\n# Uses values from the JSON file\npath, *_ = gen.generate_path(100, 200, 500, 400)\n\n# You can still override specific values\npath, *_ = gen.generate_path(\n    100, 200, 500, 400,\n    mouse_velocity=0.8  # Overrides preset velocity\n)\n</code></pre>"},{"location":"examples/tuning/","title":"Tuning Parameters","text":"<p>This guide explains how to tune path generation parameters for different behaviors.</p>"},{"location":"examples/tuning/#parameter-overview","title":"Parameter Overview","text":"Category Parameters Purpose Speed &amp; Motion <code>mouse_velocity</code>, <code>stabilization</code> Control movement speed and smoothness Correction <code>kp_start</code>, <code>kp_end</code> How aggressively path steers to target Character <code>noise</code>, <code>arc_strength</code>, <code>overshoot_prob</code> Human-like imperfections Density <code>keep_prob_start</code>, <code>keep_prob_end</code> How many points in final path"},{"location":"examples/tuning/#1-speed-fluidity","title":"1. Speed &amp; Fluidity","text":"<ul> <li><code>mouse_velocity</code>: Base movement velocity (unitless, ~0.1 to 1.0).</li> <li>Higher = Faster movement.</li> <li>Typical: <code>0.3</code> to <code>0.8</code>.</li> </ul> Value Effect 0.15 Slow, deliberate 0.35 Natural (default) 0.50 Quick, rushed <pre><code># Slow, careful movement\npath, *_ = gen.generate_path(100, 200, 500, 400, mouse_velocity=0.15)\n\n# Quick snap\npath, *_ = gen.generate_path(100, 200, 500, 400, mouse_velocity=0.50)\n</code></pre> <p>Note</p> <p>The actual velocity is modified by Fitts's Law braking - movement slows near the target regardless of speed setting.</p>"},{"location":"examples/tuning/#correction-strength-kp_start-kp_end","title":"Correction Strength (kp_start, kp_end)","text":"<p>Controls how aggressively the path corrects toward the target.</p> <ul> <li>kp_start: Correction in the first half of the path</li> <li>kp_end: Correction in the second half (fine-tuning)</li> </ul> <pre><code># Low correction = more curved, natural paths\npath, *_ = gen.generate_path(\n    100, 200, 500, 400,\n    kp_start=0.005,\n    kp_end=0.005\n)\n\n# High end correction = precise target acquisition\npath, *_ = gen.generate_path(\n    100, 200, 500, 400,\n    kp_start=0.01,\n    kp_end=0.025\n)\n</code></pre>"},{"location":"examples/tuning/#example-high-precision","title":"Example: High Precision","text":"<p>path, *_ = gen.generate_path(     100, 100, 500, 500,     mouse_velocity=0.25,     kp_end=0.03,     noise=0.05 )</p> <p>Typical Settings</p> <ul> <li>Gaming/fast: Low kp_start, moderate kp_end</li> <li>Form filling: Moderate both</li> <li>Drawing: Low both for smooth curves</li> </ul>"},{"location":"examples/tuning/#stabilization","title":"Stabilization","text":"<p>Smooths out velocity changes. Higher = smoother but less responsive.</p> Value Effect 0.0 Raw, jittery 0.15 Natural (default) 0.4 Very smooth, flowing <pre><code># Smooth, flowing curves\npath, *_ = gen.generate_path(\n    100, 200, 500, 400,\n    stabilization=0.4\n)\n</code></pre>"},{"location":"examples/tuning/#noise","title":"Noise","text":"<p>Simulates hand tremor and micro-imprecision using correlated (Ornstein-Uhlenbeck) noise.</p> Value Effect 0.0 Perfect, robotic 0.2 Slight human wobble 0.5 Noticeable tremor 1.0 Very shaky <pre><code># Add natural hand tremor\npath, *_ = gen.generate_path(\n    100, 200, 500, 400,\n    noise=0.25\n)\n</code></pre> <p>Noise Decay</p> <p>Noise automatically reduces near the target to ensure accurate endpoint arrival.</p>"},{"location":"examples/tuning/#arc-strength","title":"Arc Strength","text":"<p>Makes the path curve in an arc (like a slight bow) rather than going straight.</p> Value Effect 0.0 Straight line tendency 0.15 Subtle arc 0.3 Noticeable curve <pre><code># Curved path\npath, *_ = gen.generate_path(\n    100, 200, 500, 400,\n    arc_strength=0.2,\n    arc_sign=1  # Curve \"up\" in unit space\n)\n</code></pre>"},{"location":"examples/tuning/#example-casual-browsing","title":"Example: Casual / Browsing","text":"<p>path, *_ = gen.generate_path(     100, 100, 500, 500,     mouse_velocity=0.5,     arc_strength=0.2,     noise=1.5,     arc_sign=1  # Curve \"up\" in unit space )</p> <p>Arc Direction</p> <p>Use <code>arc_sign=1</code> or <code>arc_sign=-1</code> to control curve direction. Leave as <code>None</code> for random.</p>"},{"location":"examples/tuning/#overshoot","title":"Overshoot","text":"<p>Probability of overshooting the target and correcting back.</p> <pre><code># Sometimes overshoot (30% chance)\npath, *_ = gen.generate_path(\n    100, 200, 500, 400,\n    overshoot_prob=0.3\n)\n</code></pre>"},{"location":"examples/tuning/#example-flick-shot-panic","title":"Example: Flick Shot / Panic","text":"<p>path, *_ = gen.generate_path(     100, 100, 500, 500,     mouse_velocity=0.9,     overshoot_prob=0.8     # error_limit not supported in current version )</p>"},{"location":"examples/tuning/#point-density","title":"Point Density","text":"<p>Controls how many points are kept in the final path.</p> <ul> <li>keep_prob_start: Probability of keeping each point at path start</li> <li>keep_prob_end: Probability at path end</li> </ul> <pre><code># Sparse start, dense end (natural - fast then slow)\npath, *_ = gen.generate_path(\n    100, 200, 500, 400,\n    keep_prob_start=0.5,  # Skip ~50% of early points\n    keep_prob_end=0.99    # Keep nearly all late points\n)\n</code></pre>"},{"location":"examples/tuning/#variance","title":"Variance","text":"<p>Adds random variation to all other parameters for more natural variety.</p> <pre><code># Same settings, but each path is slightly different\nfor _ in range(5):\n    path, *_ = gen.generate_path(\n        100, 200, 500, 400,\n        mouse_velocity=0.35,\n        noise=0.2,\n        variance=0.15  # \u00b115% variation on all params\n    )\n</code></pre>"},{"location":"examples/tuning/#presets","title":"Presets","text":""},{"location":"examples/tuning/#roboticprecise","title":"Robotic/Precise","text":"<pre><code>path, *_ = gen.generate_path(\n    start_x, start_y, end_x, end_y,\n    mouse_velocity=0.3,\n    kp_start=0.02,\n    kp_end=0.02,\n    stabilization=0.1,\n    noise=0.0,\n    arc_strength=0.0\n)\n</code></pre>"},{"location":"examples/tuning/#natural-human","title":"Natural Human","text":"<pre><code>path, *_ = gen.generate_path(\n    start_x, start_y, end_x, end_y,\n    mouse_velocity=0.35,\n    kp_start=0.012,\n    kp_end=0.008,\n    stabilization=0.15,\n    noise=0.25,\n    arc_strength=0.12,\n    variance=0.1\n)\n</code></pre>"},{"location":"examples/tuning/#rushedsloppy","title":"Rushed/Sloppy","text":"<pre><code>path, *_ = gen.generate_path(\n    start_x, start_y, end_x, end_y,\n    mouse_velocity=0.5,\n    kp_start=0.008,\n    kp_end=0.015,\n    stabilization=0.1,\n    noise=0.4,\n    arc_strength=0.25,\n    overshoot_prob=0.25,\n    variance=0.2\n)\n</code></pre>"},{"location":"examples/tuning/#elderlycareful","title":"Elderly/Careful","text":"<pre><code>path, *_ = gen.generate_path(\n    start_x, start_y, end_x, end_y,\n    mouse_velocity=0.2,\n    kp_start=0.015,\n    kp_end=0.01,\n    stabilization=0.35,\n    noise=0.35,  # More tremor\n    arc_strength=0.1,\n    variance=0.15\n)\n</code></pre>"}]}